# ROOP - Face Swap Optimizado

Sistema de face swap optimizado para GPU con las versiones m√°s recientes de todas las dependencias.

## üöÄ Caracter√≠sticas

- **Versiones actualizadas**: NumPy 2.x, PyTorch 2.2.0, TensorFlow 2.16.1, ONNX Runtime 1.17.0
- **Optimizaci√≥n GPU**: Soporte completo para CUDA con configuraci√≥n optimizada
- **Procesamiento en lote**: Script optimizado para procesar m√∫ltiples videos
- **Compatibilidad**: Python 3.10+ con todas las librer√≠as actualizadas

## üìã Requisitos

- Python 3.10 o superior
- CUDA 12.1+ (para GPU)
- 8GB+ RAM (recomendado)
- FFmpeg instalado

## üõ†Ô∏è Instalaci√≥n

### Instalaci√≥n Autom√°tica (Recomendado)

```bash
# Clonar repositorio
git clone https://github.com/CDavidDv/roop
cd roop

# Instalaci√≥n autom√°tica con versiones actualizadas
python install_roop_colab.py
```

### Instalaci√≥n Manual

```bash
# Instalar dependencias
pip install -r requirements.txt

# Para entornos headless (sin GUI)
pip install -r requirements-headless.txt
```

## üéØ Uso

### Procesamiento Individual

```bash
python run_batch_processing.py \
  --source /content/source.jpg \
  --videos /content/video1.mp4 /content/video2.mp4 \
  --output-dir /content/resultados \
  --execution-threads 31 \
  --temp-frame-quality 100 \
  --keep-fps
```

### Procesamiento con GPU Optimizado

```bash
python run_roop_gpu.py \
  --source imagen.jpg \
  --target video.mp4 \
  -o resultado.mp4 \
  --frame-processor face_swapper face_enhancer \
  --execution-provider cuda \
  --execution-threads 31 \
  --temp-frame-quality 100 \
  --keep-fps
```

## ‚öôÔ∏è Par√°metros de Optimizaci√≥n

- `--execution-threads 31`: N√∫mero de hilos de procesamiento
- `--temp-frame-quality 100`: Calidad de frames temporales (0-100)
- `--keep-fps`: Mantener FPS original del video
- `--max-memory 8`: L√≠mite de memoria en GB
- `--gpu-memory-wait 30`: Tiempo de espera entre procesadores (segundos)

## üîß Optimizaciones GPU

### Configuraci√≥n Autom√°tica
- Detecci√≥n autom√°tica de GPU
- Configuraci√≥n optimizada de memoria CUDA
- Priorizaci√≥n de proveedores GPU sobre CPU
- Gesti√≥n autom√°tica de memoria del sistema

### Variables de Entorno
```bash
export TF_FORCE_GPU_ALLOW_GROWTH=true
export CUDA_VISIBLE_DEVICES=0
export TF_CPP_MIN_LOG_LEVEL=2
```

## üìä Versiones Actualizadas

| Librer√≠a | Versi√≥n | Optimizaci√≥n |
|----------|---------|--------------|
| NumPy | 2.1.4 | Compatibilidad mejorada |
| PyTorch | 2.2.0+cu121 | Soporte CUDA 12.1 |
| TensorFlow | 2.16.1 | GPU optimizado |
| ONNX Runtime | 1.17.0 | GPU acceleration |
| OpenCV | 4.9.0.80 | Rendimiento mejorado |
| InsightFace | 0.7.3 | Face detection optimizado |

## üöÄ Rendimiento

### Con GPU
- **Velocidad**: 2-5x m√°s r√°pido que CPU
- **Memoria**: Gesti√≥n autom√°tica de memoria GPU
- **Calidad**: Mantiene calidad original con optimizaciones

### Sin GPU
- **Fallback**: Procesamiento CPU optimizado
- **Hilos**: Configuraci√≥n autom√°tica de hilos
- **Memoria**: Gesti√≥n eficiente de RAM

## üîç Verificaci√≥n de Instalaci√≥n

```python
import torch
import tensorflow as tf
import onnxruntime as ort

# Verificar GPU
print(f"CUDA disponible: {torch.cuda.is_available()}")
print(f"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}")

# Verificar TensorFlow
gpus = tf.config.list_physical_devices('GPU')
print(f"GPUs TensorFlow: {len(gpus)}")

# Verificar ONNX
providers = ort.get_available_providers()
print(f"Proveedores ONNX: {providers}")
```

## üìù Notas Importantes

1. **NumPy 2.x**: Compatible con todas las librer√≠as actualizadas
2. **GPU Memory**: Configuraci√≥n autom√°tica para evitar OOM
3. **Batch Processing**: Optimizado para procesar m√∫ltiples videos
4. **NSFW Skip**: Opci√≥n para saltar verificaci√≥n NSFW en GPU

## üêõ Soluci√≥n de Problemas

### Error de Memoria GPU
```bash
# Reducir memoria m√°xima
--max-memory 4
```

### Error de CUDA
```bash
# Usar solo CPU
--execution-provider cpu
```

### Error de NumPy
```bash
# Reinstalar NumPy
pip uninstall numpy -y
pip install numpy==2.1.4
```

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Ver `LICENSE` para m√°s detalles.

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue o pull request.

---

**Optimizado para rendimiento m√°ximo con las versiones m√°s recientes de todas las dependencias.**
