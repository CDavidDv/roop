#!/usr/bin/env python3
"""
Script espec√≠fico para configurar CUDA en Google Colab
"""

import subprocess
import sys
import os

def run_command(command, description):
    """Ejecutar comando y mostrar resultado"""
    print(f"\nüîÑ {description}")
    print(f"Comando: {command}")
    print("-" * 50)
    
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        print(f"STDOUT: {result.stdout}")
        if result.stderr:
            print(f"STDERR: {result.stderr}")
        print(f"C√≥digo de salida: {result.returncode}")
        return result.returncode == 0
    except Exception as e:
        print(f"Error ejecutando comando: {e}")
        return False

def check_colab_environment():
    """Verificar si estamos en Google Colab"""
    print("üîç VERIFICANDO ENTORNO DE GOOGLE COLAB")
    print("=" * 50)
    
    try:
        import google.colab
        print("‚úÖ Ejecutando en Google Colab")
        return True
    except ImportError:
        print("‚ùå No se detect√≥ Google Colab")
        return False

def check_gpu_availability():
    """Verificar disponibilidad de GPU"""
    print("\nüîç VERIFICANDO GPU")
    print("=" * 50)
    
    # Verificar nvidia-smi
    success = run_command("nvidia-smi", "Verificando GPU con nvidia-smi")
    if not success:
        print("‚ùå GPU no disponible")
        return False
    
    # Verificar CUDA
    success = run_command("nvcc --version", "Verificando CUDA Toolkit")
    if not success:
        print("‚ùå CUDA Toolkit no disponible")
        return False
    
    print("‚úÖ GPU y CUDA disponibles")
    return True

def install_onnxruntime_gpu_colab():
    """Instalar onnxruntime-gpu espec√≠ficamente para Colab"""
    print("\nüì¶ INSTALANDO ONNX RUNTIME GPU PARA COLAB")
    print("=" * 50)
    
    # Desinstalar onnxruntime si est√° instalado
    run_command("pip uninstall -y onnxruntime", "Desinstalando onnxruntime")
    
    # Instalar onnxruntime-gpu con versi√≥n espec√≠fica para Colab
    success = run_command("pip install onnxruntime-gpu==1.16.3", "Instalando onnxruntime-gpu 1.16.3")
    if not success:
        print("‚ö†Ô∏è Intentando con versi√≥n m√°s reciente...")
        success = run_command("pip install onnxruntime-gpu", "Instalando onnxruntime-gpu")
        if not success:
            print("‚ùå Error instalando onnxruntime-gpu")
            return False
    
    # Verificar instalaci√≥n
    try:
        import onnxruntime as ort
        print(f"‚úÖ ONNX Runtime GPU instalado: {ort.__version__}")
        
        # Verificar proveedores disponibles
        providers = ort.get_available_providers()
        print(f"Proveedores disponibles: {providers}")
        
        if 'CUDAExecutionProvider' in providers:
            print("‚úÖ CUDAExecutionProvider disponible")
        else:
            print("‚ùå CUDAExecutionProvider no disponible")
            
        return True
    except ImportError:
        print("‚ùå Error importando onnxruntime-gpu")
        return False

def configure_colab_environment():
    """Configurar variables de entorno para Colab"""
    print("\n‚öôÔ∏è CONFIGURANDO ENTORNO PARA COLAB")
    print("=" * 50)
    
    # Configurar variables de entorno espec√≠ficas para Colab
    env_vars = {
        'CUDA_VISIBLE_DEVICES': '0',
        'TF_FORCE_GPU_ALLOW_GROWTH': 'true',
        'TF_CPP_MIN_LOG_LEVEL': '2',
        'OMP_NUM_THREADS': '1',
        'CUDA_LAUNCH_BLOCKING': '1',
        'CUDA_CACHE_DISABLE': '0',
        'CUDA_CACHE_PATH': '/tmp/cuda_cache'
    }
    
    for var, value in env_vars.items():
        os.environ[var] = value
        print(f"‚úÖ {var}={value}")
    
    return True

def test_cuda_creation():
    """Probar creaci√≥n de sesi√≥n CUDA"""
    print("\nüß™ PROBANDO CREACI√ìN DE SESI√ìN CUDA")
    print("=" * 50)
    
    try:
        import onnxruntime as ort
        import numpy as np
        from onnx import helper
        
        # Crear modelo simple para probar
        X = helper.make_tensor_value_info('X', helper.TensorProto.FLOAT, [1, 3, 224, 224])
        Y = helper.make_tensor_value_info('Y', helper.TensorProto.FLOAT, [1, 3, 224, 224])
        node = helper.make_node('Identity', inputs=['X'], outputs=['Y'])
        graph = helper.make_graph([node], 'test', [X], [Y])
        model = helper.make_model(graph)
        
        # Intentar diferentes configuraciones
        configs_to_try = [
            {
                'providers': ['CUDAExecutionProvider'],
                'options': {
                    'CUDAExecutionProvider': {
                        'device_id': 0,
                        'arena_extend_strategy': 'kNextPowerOfTwo',
                        'gpu_mem_limit': 2 * 1024 * 1024 * 1024,
                        'cudnn_conv_use_max_workspace': '1',
                        'do_copy_in_default_stream': '1',
                    }
                }
            },
            {
                'providers': ['CUDAExecutionProvider', 'CPUExecutionProvider'],
                'options': {
                    'CUDAExecutionProvider': {
                        'device_id': 0,
                        'arena_extend_strategy': 'kNextPowerOfTwo',
                        'gpu_mem_limit': 2 * 1024 * 1024 * 1024,
                    }
                }
            },
            {
                'providers': ['CUDAExecutionProvider'],
                'options': {}
            }
        ]
        
        for i, config in enumerate(configs_to_try):
            try:
                print(f"Probando configuraci√≥n {i+1}: {config['providers']}")
                
                session = ort.InferenceSession(
                    model.SerializeToString(),
                    providers=config['providers'],
                    provider_options=config['options']
                )
                
                actual_providers = session.get_providers()
                print(f"‚úÖ Sesi√≥n creada exitosamente")
                print(f"Proveedores aplicados: {actual_providers}")
                
                if any('CUDA' in provider for provider in actual_providers):
                    print("‚úÖ CUDA confirmado en uso")
                    return True
                else:
                    print("‚ö†Ô∏è CUDA no confirmado, intentando siguiente configuraci√≥n...")
                    continue
                    
            except Exception as e:
                print(f"‚ùå Error con configuraci√≥n {i+1}: {e}")
                continue
        
        print("‚ùå Ninguna configuraci√≥n funcion√≥")
        return False
        
    except Exception as e:
        print(f"‚ùå Error en prueba de CUDA: {e}")
        return False

def test_face_swapper_gpu():
    """Probar face swapper con GPU"""
    print("\nüé≠ PROBANDO FACE SWAPPER CON GPU")
    print("=" * 50)
    
    try:
        import roop.processors.frame.face_swapper as face_swapper
        
        print("Cargando modelo de face swapper...")
        swapper = face_swapper.get_face_swapper()
        
        if swapper:
            print("‚úÖ Face swapper cargado exitosamente")
            
            if hasattr(swapper, 'providers'):
                actual_providers = swapper.providers
                print(f"Proveedores del modelo: {actual_providers}")
                
                if any('CUDA' in provider for provider in actual_providers):
                    print("‚úÖ GPU CUDA confirmado en uso para face swapper")
                    return True
                else:
                    print("‚ùå GPU CUDA no confirmado para face swapper")
                    return False
            else:
                print("Modelo cargado (no se puede verificar proveedores)")
                return True  # Asumimos que funciona si no podemos verificar
        else:
            print("‚ùå Error cargando face swapper")
            return False
            
    except Exception as e:
        print(f"‚ùå Error probando face swapper: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Funci√≥n principal"""
    print("üöÄ CONFIGURADOR DE CUDA PARA GOOGLE COLAB")
    print("=" * 60)
    
    # Verificar entorno de Colab
    if not check_colab_environment():
        print("‚ö†Ô∏è Continuando sin verificaci√≥n de Colab...")
    
    # Verificar GPU
    if not check_gpu_availability():
        print("‚ùå GPU no disponible")
        return False
    
    # Instalar onnxruntime-gpu
    if not install_onnxruntime_gpu_colab():
        print("‚ùå Error instalando onnxruntime-gpu")
        return False
    
    # Configurar entorno
    configure_colab_environment()
    
    # Probar creaci√≥n de sesi√≥n CUDA
    if not test_cuda_creation():
        print("‚ùå Error creando sesi√≥n CUDA")
        return False
    
    # Probar face swapper
    if not test_face_swapper_gpu():
        print("‚ùå Error con face swapper")
        return False
    
    print("\nüéâ ¬°CONFIGURACI√ìN COMPLETADA EXITOSAMENTE!")
    print("‚úÖ CUDA est√° funcionando correctamente")
    print("‚úÖ Face swapper est√° usando GPU")
    print("‚úÖ Puedes ejecutar python test_gpu_force.py para verificar")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 