# ROOP - Face Swap Optimizado para GPU

Este proyecto ha sido actualizado para aprovechar al m√°ximo el hardware disponible, especialmente las GPU, con versiones recientes de todas las librer√≠as y optimizaciones de rendimiento.

## üöÄ Caracter√≠sticas Principales

- **Optimizaci√≥n GPU**: Soporte completo para CUDA con PyTorch y ONNX Runtime
- **Versiones Actualizadas**: Todas las dependencias actualizadas a versiones recientes
- **Compatibilidad Python 3.10+**: Optimizado para versiones modernas de Python
- **Gesti√≥n de Memoria**: Optimizaci√≥n autom√°tica de memoria GPU y CPU
- **Procesamiento en Lote**: Mantiene la funcionalidad de procesamiento m√∫ltiple
- **Detecci√≥n Autom√°tica**: Detecta autom√°ticamente el hardware disponible

## üìã Requisitos del Sistema

### M√≠nimos
- Python 3.10 o superior
- 8GB RAM
- GPU NVIDIA con CUDA 11.8+ (recomendado)
- 10GB espacio libre

### Recomendados
- Python 3.11+
- 16GB+ RAM
- GPU NVIDIA RTX 3060+ con 8GB+ VRAM
- SSD para mejor rendimiento

## üõ†Ô∏è Instalaci√≥n

### 1. Instalaci√≥n Autom√°tica (Recomendada)

```bash
# Clonar el repositorio
git clone <repository-url>
cd roop

# Ejecutar instalaci√≥n autom√°tica
python install_updated.py
```

### 2. Instalaci√≥n Manual

```bash
# Actualizar pip
python -m pip install --upgrade pip

# Instalar dependencias base
pip install -r requirements.txt

# Verificar instalaci√≥n GPU
python gpu_optimization.py
```

## üîß Verificaci√≥n de GPU

Ejecute el script de verificaci√≥n para confirmar que todo est√° configurado correctamente:

```bash
python gpu_optimization.py
```

Este script verificar√°:
- ‚úÖ Instalaci√≥n de CUDA
- ‚úÖ PyTorch con soporte GPU
- ‚úÖ ONNX Runtime con CUDA
- ‚úÖ TensorFlow con GPU
- ‚úÖ Configuraci√≥n de variables de entorno

## üéØ Uso

### Comando Principal

El comando de ejecuci√≥n se mantiene igual:

```bash
python run_batch_processing.py --source /content/source.jpg --videos /content/video1.mp4 /content/video2.mp4 --output-dir /content/resultados --execution-threads 31 --temp-frame-quality 100 --keep-fps
```

### Par√°metros Optimizados

- `--execution-threads`: Se optimiza autom√°ticamente seg√∫n el hardware
- `--gpu-memory-wait`: Tiempo de espera entre procesadores (default: 30s)
- `--max-memory`: Memoria m√°xima en GB (default: 8GB)
- `--temp-frame-quality`: Calidad de frames temporales (default: 100)

### Ejemplos de Uso

```bash
# Procesamiento b√°sico
python run_batch_processing.py --source source.jpg --videos video1.mp4 video2.mp4 --output-dir resultados

# Procesamiento optimizado para GPU
python run_batch_processing.py --source source.jpg --videos video1.mp4 --output-dir resultados --execution-threads 16 --gpu-memory-wait 15

# Procesamiento con configuraci√≥n personalizada
python run_batch_processing.py --source source.jpg --videos video1.mp4 video2.mp4 video3.mp4 --output-dir resultados --temp-frame-quality 95 --keep-fps
```

## ‚ö° Optimizaciones Implementadas

### GPU
- **CUDA 12.1**: Soporte para la versi√≥n m√°s reciente de CUDA
- **ONNX Runtime GPU**: Optimizaci√≥n para inferencia con GPU
- **PyTorch GPU**: Aceleraci√≥n de operaciones de deep learning
- **Gesti√≥n de Memoria**: Liberaci√≥n autom√°tica de memoria GPU

### CPU
- **Procesamiento Paralelo**: Optimizaci√≥n autom√°tica de hilos
- **Gesti√≥n de Memoria**: Control de uso de RAM
- **Detecci√≥n de Hardware**: Configuraci√≥n autom√°tica seg√∫n CPU

### Librer√≠as Actualizadas
- **PyTorch 2.2.0**: Versi√≥n m√°s reciente con optimizaciones
- **TensorFlow 2.16.1**: Mejoras de rendimiento
- **ONNX Runtime 1.17.0**: Mejor soporte GPU
- **OpenCV 4.9.0**: Optimizaciones de procesamiento de imagen

## üîç Monitoreo de Rendimiento

El proyecto incluye monitoreo autom√°tico de:
- Uso de memoria GPU
- Uso de memoria RAM
- Progreso de procesamiento
- Optimizaci√≥n autom√°tica de hilos

## üêõ Soluci√≥n de Problemas

### GPU no detectada
```bash
# Verificar instalaci√≥n CUDA
nvidia-smi

# Verificar PyTorch GPU
python -c "import torch; print(torch.cuda.is_available())"
```

### Error de memoria
- Reduzca `--max-memory` a un valor menor
- Aumente `--gpu-memory-wait` para m√°s tiempo entre procesadores
- Reduzca `--execution-threads`

### Error de dependencias
```bash
# Reinstalar dependencias
pip install --force-reinstall -r requirements.txt

# Verificar versi√≥n Python
python --version
```

## üìä Comparaci√≥n de Rendimiento

| Configuraci√≥n | CPU (Intel i7) | GPU (RTX 3060) | GPU (RTX 4090) |
|---------------|----------------|----------------|----------------|
| Tiempo por frame | ~2s | ~0.3s | ~0.1s |
| Memoria usada | 8GB RAM | 4GB RAM + 2GB VRAM | 4GB RAM + 4GB VRAM |
| Hilos √≥ptimos | 16 | 8 | 12 |

## üîÑ Actualizaciones

### v2.0 (Actual)
- ‚úÖ Actualizaci√≥n completa de dependencias
- ‚úÖ Optimizaci√≥n GPU con CUDA 12.1
- ‚úÖ Gesti√≥n autom√°tica de memoria
- ‚úÖ Detecci√≥n autom√°tica de hardware
- ‚úÖ Compatibilidad Python 3.10+

### v1.0 (Anterior)
- ‚ùå Versiones antiguas de librer√≠as
- ‚ùå Sin optimizaci√≥n GPU
- ‚ùå Gesti√≥n manual de memoria
- ‚ùå Configuraci√≥n manual

## ü§ù Contribuciones

Para contribuir al proyecto:

1. Fork el repositorio
2. Cree una rama para su feature
3. Commit sus cambios
4. Push a la rama
5. Abra un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Vea el archivo `LICENSE` para m√°s detalles.

## üôè Agradecimientos

- InsightFace por el modelo de face swap
- PyTorch y ONNX Runtime por el soporte GPU
- La comunidad de ROOP por el proyecto original

---

**¬°Disfrute del procesamiento de face swap optimizado! üéâ** 