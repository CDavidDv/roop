#!/usr/bin/env python3
"""
Instalaci√≥n oficial de TensorFlow GPU para Google Colab
"""

import os
import sys
import subprocess

def install_colab_tensorflow():
    """Instalar TensorFlow GPU oficial para Colab"""
    print("üöÄ INSTALANDO TENSORFLOW GPU OFICIAL PARA COLAB:")
    print("=" * 60)
    
    try:
        # Desinstalar TensorFlow actual
        print("‚è≥ Desinstalando TensorFlow actual...")
        cmd1 = [sys.executable, "-m", "pip", "uninstall", "-y", "tensorflow", "tensorflow-gpu"]
        subprocess.run(cmd1, check=True, capture_output=True, text=True)
        
        # Instalar TensorFlow GPU oficial para Colab
        print("‚è≥ Instalando TensorFlow GPU para Colab...")
        cmd2 = [
            sys.executable, "-m", "pip", "install",
            "tensorflow[gpu]==2.13.0"
        ]
        subprocess.run(cmd2, check=True, capture_output=True, text=True)
        
        print("‚úÖ TensorFlow GPU instalado")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Error instalando TensorFlow: {e}")
        return False

def install_colab_gpu_dependencies():
    """Instalar dependencias GPU espec√≠ficas de Colab"""
    print("\nüì¶ INSTALANDO DEPENDENCIAS GPU COLAB:")
    print("=" * 40)
    
    try:
        # Instalar dependencias GPU
        dependencies = [
            "nvidia-ml-py3",
            "pynvml",
            "onnxruntime-gpu",
            "torch",
            "torchvision"
        ]
        
        for dep in dependencies:
            print(f"‚è≥ Instalando {dep}...")
            cmd = [sys.executable, "-m", "pip", "install", dep]
            subprocess.run(cmd, check=True, capture_output=True, text=True)
        
        print("‚úÖ Dependencias GPU instaladas")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Error instalando dependencias: {e}")
        return False

def setup_colab_gpu_env():
    """Configurar entorno GPU para Colab"""
    print("\nüîß CONFIGURANDO ENTORNO GPU COLAB:")
    print("=" * 40)
    
    # Variables de entorno espec√≠ficas para Colab
    env_vars = {
        'CUDA_VISIBLE_DEVICES': '0',
        'TF_FORCE_GPU_ALLOW_GROWTH': 'true',
        'TF_CPP_MIN_LOG_LEVEL': '0',
        'TF_FORCE_UNIFIED_MEMORY': '1',
        'TF_MEMORY_ALLOCATION': '0.9',
        'TF_GPU_MEMORY_LIMIT': '14',
        'TF_CUDNN_USE_AUTOTUNE': '0',
        'TF_CUDNN_DETERMINISTIC': '1',
        # Variables espec√≠ficas para Colab
        'XLA_PYTHON_CLIENT_PREALLOCATE': 'false',
        'XLA_PYTHON_CLIENT_ALLOCATOR': 'platform'
    }
    
    for var, value in env_vars.items():
        os.environ[var] = value
        print(f"‚úÖ {var} = {value}")
    
    print("‚úÖ Variables de entorno configuradas")

def test_colab_gpu():
    """Probar GPU en Colab"""
    print("\nüß™ PROBANDO GPU COLAB:")
    print("=" * 40)
    
    try:
        import tensorflow as tf
        print(f"‚úÖ TensorFlow version: {tf.__version__}")
        
        # Verificar dispositivos
        devices = tf.config.list_physical_devices()
        print(f"üì± Dispositivos disponibles: {len(devices)}")
        for device in devices:
            print(f"  - {device}")
        
        # Verificar GPU espec√≠ficamente
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            print(f"üéÆ GPU disponible: {len(gpus)} dispositivos")
            for gpu in gpus:
                print(f"  - {gpu}")
            
            # Configurar GPU
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print("‚úÖ GPU configurado para crecimiento de memoria")
            
            # Probar operaci√≥n en GPU
            with tf.device('/GPU:0'):
                a = tf.constant([[1.0, 2.0], [3.0, 4.0]])
                b = tf.constant([[1.0, 1.0], [0.0, 1.0]])
                c = tf.matmul(a, b)
                print(f"‚úÖ Operaci√≥n GPU exitosa: {c}")
            
            return True
        else:
            print("‚ùå GPU no disponible")
            return False
            
    except Exception as e:
        print(f"‚ùå Error probando GPU: {e}")
        return False

def create_colab_gpu_wrapper_final():
    """Crear wrapper final para Colab GPU"""
    print("\nüìù CREANDO WRAPPER FINAL COLAB GPU:")
    print("=" * 40)
    
    wrapper_content = '''#!/usr/bin/env python3
"""
Wrapper final para ROOP con GPU en Google Colab
"""

import os
import sys
import subprocess

# CONFIGURACI√ìN FINAL PARA COLAB GPU
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'
os.environ['TF_FORCE_UNIFIED_MEMORY'] = '1'
os.environ['TF_MEMORY_ALLOCATION'] = '0.9'
os.environ['TF_GPU_MEMORY_LIMIT'] = '14'
os.environ['TF_CUDNN_USE_AUTOTUNE'] = '0'
os.environ['TF_CUDNN_DETERMINISTIC'] = '1'
os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'
os.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform'

def check_colab_gpu_final():
    try:
        import tensorflow as tf
        print(f"üéÆ TensorFlow version: {tf.__version__}")
        
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            print(f"‚úÖ GPU detectada: {len(gpus)} dispositivos")
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print("‚úÖ GPU configurado para Colab")
            return True
        else:
            print("‚ùå GPU no disponible en Colab")
            return False
    except Exception as e:
        print(f"‚ùå Error verificando GPU: {e}")
        return False

def main():
    """Funci√≥n principal"""
    print("üöÄ ROOP CON GPU COLAB FINAL")
    print("=" * 40)
    
    # Verificar GPU
    if not check_colab_gpu_final():
        print("‚ùå No se puede continuar sin GPU")
        return False
    
    # Obtener argumentos
    args = sys.argv[1:]
    
    # Construir comando
    cmd = [sys.executable, 'run.py'] + args
    
    print(f"üöÄ Ejecutando: {' '.join(cmd)}")
    print("=" * 40)
    
    try:
        # Ejecutar ROOP
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        print("‚úÖ ROOP ejecutado exitosamente")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Error ejecutando ROOP:")
        print(f"STDOUT: {e.stdout}")
        print(f"STDERR: {e.stderr}")
        return False

if __name__ == '__main__':
    main()
'''
    
    try:
        with open('run_roop_colab_gpu_final.py', 'w') as f:
            f.write(wrapper_content)
        print("‚úÖ Wrapper final creado: run_roop_colab_gpu_final.py")
        return True
    except Exception as e:
        print(f"‚ùå Error creando wrapper: {e}")
        return False

def update_roop_script_final():
    """Actualizar script principal para usar wrapper final"""
    print("\nüìù ACTUALIZANDO SCRIPT PRINCIPAL FINAL:")
    print("=" * 40)
    
    script_file = 'run_roop_original_gpu.py'
    
    if not os.path.exists(script_file):
        print(f"‚ùå Archivo {script_file} no encontrado")
        return False
    
    try:
        with open(script_file, 'r') as f:
            content = f.read()
        
        # Reemplazar comando para usar wrapper final
        old_cmd = "sys.executable, 'run_roop_colab_gpu.py'"
        new_cmd = "sys.executable, 'run_roop_colab_gpu_final.py'"
        
        if old_cmd in content:
            content = content.replace(old_cmd, new_cmd)
        else:
            # Buscar otros comandos
            old_cmds = [
                "sys.executable, 'run_roop_gpu_forced.py'",
                "sys.executable, 'run_roop_wrapper.py'"
            ]
            for old_cmd in old_cmds:
                if old_cmd in content:
                    content = content.replace(old_cmd, new_cmd)
                    break
            else:
                print("‚ö†Ô∏è No se encontr√≥ comando a reemplazar")
                return False
        
        with open(script_file, 'w') as f:
            f.write(content)
        
        print("‚úÖ Script actualizado para usar wrapper final")
        return True
        
    except Exception as e:
        print(f"‚ùå Error actualizando script: {e}")
        return False

def main():
    """Funci√≥n principal"""
    print("üöÄ INSTALACI√ìN TENSORFLOW GPU OFICIAL COLAB")
    print("=" * 60)
    
    # Instalar TensorFlow GPU oficial
    if not install_colab_tensorflow():
        print("‚ùå Error instalando TensorFlow GPU")
        return False
    
    # Instalar dependencias GPU
    if not install_colab_gpu_dependencies():
        print("‚ùå Error instalando dependencias GPU")
        return False
    
    # Configurar entorno GPU
    setup_colab_gpu_env()
    
    # Crear wrapper final
    if not create_colab_gpu_wrapper_final():
        print("‚ùå Error creando wrapper final")
        return False
    
    # Actualizar script principal
    update_roop_script_final()
    
    # Probar GPU
    if not test_colab_gpu():
        print("‚ùå Error: GPU no funciona en Colab")
        return False
    
    print("\n‚úÖ TENSORFLOW GPU COLAB INSTALADO EXITOSAMENTE")
    print("=" * 60)
    print("üìã PR√ìXIMOS PASOS:")
    print("1. Procesar videos: python run_roop_original_gpu.py --source imagen.jpg --input-folder videos_entrada --output-dir videos_salida")
    print("2. O usar wrapper directamente: python run_roop_colab_gpu_final.py --source imagen.jpg --target video.mp4 -o resultado.mp4")
    print("3. Verificar uso GPU: Deber√≠as ver 8-12 GB de VRAM en uso")
    
    return True

if __name__ == '__main__':
    main() 