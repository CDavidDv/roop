# ðŸš€ GUÃA COMPLETA: ROOP CON GPU TESLA T4 (15GB)

## ðŸ“‹ **Ãndice**
1. [VerificaciÃ³n Inicial](#verificaciÃ³n-inicial)
2. [InstalaciÃ³n de ONNX Runtime GPU](#instalaciÃ³n-de-onnx-runtime-gpu)
3. [ConfiguraciÃ³n de GPU](#configuraciÃ³n-de-gpu)
4. [Monitoreo de Recursos](#monitoreo-de-recursos)
5. [Procesamiento Optimizado](#procesamiento-optimizado)
6. [SoluciÃ³n de Problemas](#soluciÃ³n-de-problemas)

---

## ðŸ” **1. VerificaciÃ³n Inicial**

### **Paso 1.1: Verificar GPU**
```bash
nvidia-smi
```
**Resultado esperado:**
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |
| N/A   45C    P0    70W /  70W |      0MiB / 15360MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
```

### **Paso 1.2: Verificar Environment**
```bash
ls roop_env/bin/python
```
**Resultado esperado:**
```
roop_env/bin/python
```

### **Paso 1.3: Verificar ONNX Runtime Actual**
```bash
roop_env/bin/python -c "import onnxruntime as ort; print('VersiÃ³n:', ort.__version__); print('Proveedores:', ort.get_available_providers())"
```
**Resultado esperado (PROBLEMA):**
```
VersiÃ³n: 1.15.1
Proveedores: ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
```

---

## ðŸ“¦ **2. InstalaciÃ³n de ONNX Runtime GPU**

### **Paso 2.1: Ejecutar Instalador AutomÃ¡tico**
```bash
python install_onnxruntime_gpu_env.py
```

### **Paso 2.2: Verificar InstalaciÃ³n**
```bash
roop_env/bin/python -c "import onnxruntime as ort; print('VersiÃ³n:', ort.__version__); print('GPU:', 'gpu' in ort.__version__.lower())"
```
**Resultado esperado:**
```
VersiÃ³n: 1.15.1
GPU: True
```

### **Paso 2.3: Probar GPU**
```bash
roop_env/bin/python -c "import onnxruntime as ort; session = ort.InferenceSession('test.onnx', providers=['CUDAExecutionProvider']); print('âœ… GPU funciona')"
```

---

## âš™ï¸ **3. ConfiguraciÃ³n de GPU**

### **Paso 3.1: Aplicar Forzado de GPU**
```bash
python force_gpu_face_swapper.py
```

### **Paso 3.2: Verificar ConfiguraciÃ³n**
```bash
python fix_face_swapper_gpu.py
```

### **Paso 3.3: Crear Script de Entorno**
```bash
# El script crearÃ¡ automÃ¡ticamente: run_roop_gpu_env.sh
```

---

## ðŸ“Š **4. Monitoreo de Recursos**

### **Paso 4.1: Monitoreo en Tiempo Real**
```bash
# Terminal 1: Monitoreo GPU
python monitor_gpu_live.py

# Terminal 2: Monitoreo especÃ­fico
python check_gpu_usage.py
```

### **Paso 4.2: Verificar Recursos**
```bash
nvidia-smi -l 1
```

---

## ðŸš€ **5. Procesamiento Optimizado**

### **OpciÃ³n 5.1: Procesamiento Individual**
```bash
./run_roop_gpu_env.sh \
  --source /content/DanielaAS.jpg \
  --target /content/112.mp4 \
  -o /content/DanielaAS112_gpu.mp4 \
  --frame-processor face_swapper \
  --execution-provider cuda \
  --max-memory 8 \
  --execution-threads 8 \
  --gpu-memory-wait 5 \
  --temp-frame-quality 100 \
  --temp-frame-format png \
  --output-video-encoder h264_nvenc \
  --output-video-quality 100 \
  --keep-fps
```

### **OpciÃ³n 5.2: Procesamiento en Lote**
```bash
roop_env/bin/python run_batch_processing_clean.py \
  --source /content/DanielaAS.jpg \
  --videos /content/62.mp4 /content/71.mp4 /content/72.mp4 /content/74.mp4 /content/75.mp4 /content/76.mp4 /content/77.mp4 /content/78.mp4 /content/79.mp4 \
  --output-dir /content/resultados \
  --keep-fps
```

### **OpciÃ³n 5.3: Procesamiento Optimizado para 15GB**
```bash
roop_env/bin/python run_batch_processing_optimized.py \
  --source /content/DanielaAS.jpg \
  --videos /content/62.mp4 /content/71.mp4 /content/72.mp4 /content/74.mp4 /content/75.mp4 /content/76.mp4 /content/77.mp4 /content/78.mp4 /content/79.mp4 \
  --output-dir /content/resultados \
  --keep-fps
```

---

## ðŸ“ˆ **6. Monitoreo Durante Procesamiento**

### **Lo que DeberÃ­as Ver:**

#### **âœ… GPU Funcionando Correctamente:**
```
ðŸ”„ [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 40% | Frame 61/152 | â±ï¸ 00:45 | â³ 01:15 | ðŸš€ 1.2s/frame | ðŸ§  2.8GB | ðŸŽ® 8.5GB VRAM

ðŸ“Š [14:30:25] GPU: 8500MB/15360MB (55.3%) | RAM: 6.8GB/12.7GB (53.5%) | Temp: 68Â°C
```

#### **âŒ GPU NO Funcionando:**
```
ðŸ”„ [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 40% | Frame 61/152 | â±ï¸ 02:15 | â³ 03:25 | ðŸš€ 6.3s/frame | ðŸ§  2.8GB | ðŸŽ® 0.0GB VRAM
```

---

## ðŸ”§ **7. SoluciÃ³n de Problemas**

### **Problema 1: VRAM = 0.0GB**
```bash
# SoluciÃ³n: Reinstalar ONNX Runtime GPU
python install_onnxruntime_gpu_env.py
```

### **Problema 2: Error CUDA**
```bash
# SoluciÃ³n: Verificar drivers
nvidia-smi
nvcc --version
```

### **Problema 3: Lento (6s/frame)**
```bash
# SoluciÃ³n: Forzar GPU
python force_gpu_face_swapper.py
```

### **Problema 4: Error de Memoria**
```bash
# SoluciÃ³n: Reducir memoria
--max-memory 6 --gpu-memory-wait 15
```

---

## ðŸ“Š **8. ComparaciÃ³n de Rendimiento**

| **ConfiguraciÃ³n** | **Velocidad** | **VRAM** | **Tiempo Total** |
|-------------------|---------------|----------|------------------|
| **CPU (Antes)** | 6.3s/frame | 0.0GB | 30-60 min |
| **GPU (DespuÃ©s)** | 1.2s/frame | 8.5GB | 5-10 min |
| **Mejora** | **5x mÃ¡s rÃ¡pido** | **GPU activa** | **6x mÃ¡s rÃ¡pido** |

---

## ðŸŽ¯ **9. Comandos RÃ¡pidos**

### **VerificaciÃ³n RÃ¡pida:**
```bash
# Verificar GPU
nvidia-smi

# Verificar ONNX
roop_env/bin/python -c "import onnxruntime as ort; print('GPU:', 'gpu' in ort.__version__.lower())"

# Procesar un video
./run_roop_gpu_env.sh --source imagen.jpg --target video.mp4 -o salida.mp4 --frame-processor face_swapper --execution-provider cuda
```

### **Monitoreo RÃ¡pido:**
```bash
# Terminal 1
python monitor_gpu_live.py

# Terminal 2
nvidia-smi -l 1
```

---

## âœ… **10. Checklist Final**

- [ ] GPU Tesla T4 detectada
- [ ] ONNX Runtime GPU instalado en environment
- [ ] Face-swapper modificado para GPU
- [ ] Script de entorno creado
- [ ] Monitoreo configurado
- [ ] Procesamiento funcionando con VRAM > 0GB
- [ ] Velocidad mejorada (1-2s/frame)

---

## ðŸš€ **11. EjecuciÃ³n Final**

```bash
# 1. Verificar todo
python install_onnxruntime_gpu_env.py

# 2. Aplicar optimizaciones
python force_gpu_face_swapper.py

# 3. Procesar con GPU
./run_roop_gpu_env.sh \
  --source /content/DanielaAS.jpg \
  --target /content/112.mp4 \
  -o /content/DanielaAS112_gpu.mp4 \
  --frame-processor face_swapper \
  --execution-provider cuda \
  --max-memory 8 \
  --execution-threads 8 \
  --gpu-memory-wait 5 \
  --temp-frame-quality 100 \
  --temp-frame-format png \
  --output-video-encoder h264_nvenc \
  --output-video-quality 100 \
  --keep-fps

# 4. Monitorear
python monitor_gpu_live.py
```

**Â¡Con esta guÃ­a completa tendrÃ¡s ROOP funcionando al mÃ¡ximo con tu GPU Tesla T4 de 15GB!** ðŸŽ‰ 